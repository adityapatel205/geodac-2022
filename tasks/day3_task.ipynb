{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8a473b7",
   "metadata": {},
   "source": [
    "## Interpolating real data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc5da34",
   "metadata": {},
   "source": [
    "##### Go through the [Interpolation Guide](https://github.com/tww-carleton/geodac-2022/blob/main/notebooks/InterpolationGuide.ipynb) before this challenge!\n",
    "\n",
    "A common problem when working with satellite data is that the resolution of the data product may not match with other data or models to which you want to compare. Interpolation, or re-gridding, takes data specified on a particular set of geospatial coordinates and converts it onto another. This is common, but we want the process to be as error-free as possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cae594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d52f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use your own data files \n",
    "\n",
    "ds  = xr.load_dataset('air.sig995.1948.nc').isel(time=0)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d08c97-b63f-46fb-b613-7c8b13f50fce",
   "metadata": {},
   "source": [
    "Here, we are showing an alternative way to deal with some NetCDF files: xarray. An xarray dataset already behaves much like a pandas dataframe, and can also easily be plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d4d6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2,figsize=(25, 10))\n",
    "\n",
    "ds.air.plot(ax=axes[0],robust=True)\n",
    "\n",
    "axes[0].set_title(\"Raw data\")\n",
    "\n",
    "# This defines a new longitude and latitude grid, at higher resolution than the original\n",
    "new_lon = np.linspace(ds.lon[0], ds.lon[-2], ds.dims[\"lon\"] * 5)\n",
    "new_lat = np.linspace(ds.lat[0], ds.lat[-2], ds.dims[\"lat\"] * 5)\n",
    "\n",
    "print (new_lat)\n",
    "\n",
    "# The interp() command interpolates the data onto the new grid\n",
    "dsi = ds.interp(lat=new_lat, lon=new_lon)\n",
    "\n",
    "dsi.air.plot(ax=axes[1],robust=True)\n",
    "\n",
    "axes[1].set_title(\"Interpolated data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e365b0f",
   "metadata": {},
   "source": [
    "It can be observed that using spatial interpolation we have reduced the grid size and estimated the air temperature values at finer resolution.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>WARNING!</b> This does not mean that we are creating new information. Even though the array might have more elements, the amount of information contained in the original data has been averaged over those new elements. The interp() command assumes that the field between adjacent points is smooth and creates an estimate based on surrounding values.\n",
    "</div>\n",
    "\n",
    "Usually if we are comparing two datasets, we would resample the higher resolution product down to the coarser grid.\n",
    "\n",
    "Consider the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13da3c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old coordinate system\n",
    "\n",
    "x = np.linspace(240, 300, 100)\n",
    "\n",
    "z = np.linspace(20, 70, 100)\n",
    "\n",
    "# Relation between new (lat, lon) and original (x, z) coordinates\n",
    "lat = xr.DataArray(z, dims=[\"z\"], coords={\"z\": z})\n",
    "\n",
    "lon = xr.DataArray(\n",
    "    (x[:, np.newaxis] - 270) / np.cos(z * np.pi / 180) + 270,\n",
    "    dims=[\"x\", \"z\"],\n",
    "    coords={\"x\": x, \"z\": z},\n",
    ")\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 4))\n",
    "\n",
    "ds.air.plot(ax=axes[0])\n",
    "\n",
    "\n",
    "# draw the new coordinate on the original coordinates.\n",
    "for idx in [0, 33, 66, 99]:\n",
    "    axes[0].plot(lon.isel(x=idx), lat, \"--k\")\n",
    "\n",
    "\n",
    "for idx in [0, 33, 66, 99]:\n",
    "    axes[0].plot(*xr.broadcast(lon.isel(z=idx), lat.isel(z=idx)), \"--k\")\n",
    "\n",
    "\n",
    "axes[0].set_title(\"Raw data\")\n",
    "\n",
    "dsi = ds.interp(lon=lon, lat=lat)\n",
    "\n",
    "dsi.air.plot(ax=axes[1])\n",
    "\n",
    "axes[1].set_title(\"Remapped data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa77841",
   "metadata": {},
   "source": [
    "### Saving your work "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7316166b",
   "metadata": {},
   "source": [
    "#### Saving Datasets and DataArrays to NetCDF\n",
    "\n",
    "Saving your Datasets and DataArrays objects to NetCDF files couldn’t be simpler. The xarray module that we’ve been using to load NetCDF files provides methods for saving your Datasets and DataArrays as NetCDF files.\n",
    "\n",
    "Here is the manual page on the subjet: http://xarray.pydata.org/en/stable/generated/xarray.Dataset.to_netcdf.html\n",
    "\n",
    "The method ._to_netcdf( ) is available to both Datasets and DataArrays objects. \n",
    "\n",
    "#### Syntax\n",
    "\n",
    "*your_dataset.to_netcdf('/your_filepath/your_netcdf_filename.nc')*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4673bbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsi.to_netcdf(path='C:\\\\(add your path)\\challenge3_output.nc')\n",
    "print ('finished saving')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8f3e25",
   "metadata": {},
   "source": [
    "## Try it yourself!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc2d44d",
   "metadata": {},
   "source": [
    "#### 1. Use the data files we used in the last two tasks. Read in the latitude and longitude for each data file, and the nitrogendioxide_tropospheric_column from the TROPOMI file.\n",
    "\n",
    "    Use interp to put the nitrogendioxide_tropospheric_column TROPOMI data onto the grid from the VIIRS file. Create maps showing the data before and after the interpolation. Save the result to a single NetCDF file, along with both coordinate grids.\n",
    "    \n",
    "#### 2. This interp() function is great... if its assumptions are met. What if the pixels in one of your grids aren't all the same size? Or, what if the uncertainty on some of the measurements is much greater than others? You may want to do a weighted average of some kind.\n",
    "\n",
    "    Have a close look at the boundaries of the TROPOMI data (look at /PRODUCT/SUPPORT_DATA/GEOLOCATIONS/latitude_bounds and longitude_bounds). Are all the TROPOMI pixels the same size? How might you construct a weighted average so that equal areas get equal weight in the re-gridded product?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GEODACenv",
   "language": "python",
   "name": "geodacenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
